{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:36.188538Z",
     "start_time": "2021-01-28T07:14:34.715983Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import myfm\n",
    "from myfm import RelationBlock\n",
    "import pandas as pd\n",
    "from scipy import sparse as sps\n",
    "# read movielens 100k data.\n",
    "from myfm.utils.benchmark_data import MovieLens100kDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:36.319013Z",
     "start_time": "2021-01-28T07:14:36.198144Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = np.load('../data/douban/data/douban.npy', allow_pickle=True)\n",
    "train = np.load('../data/douban/data/otraining.npy', allow_pickle=True) * ratings\n",
    "val = np.load('../data/douban/data/otest.npy', allow_pickle=True) * ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:37.083008Z",
     "start_time": "2021-01-28T07:14:36.331561Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(\n",
    "    list(zip(*train.nonzero(), list(map(lambda x: train[x[0], x[1]], zip(*train.nonzero()))))),\n",
    "    columns=['user_id', 'movie_id', 'rating']\n",
    ")\n",
    "df_test = pd.DataFrame(\n",
    "    list(zip(*val.nonzero(), list(map(lambda x: val[x[0], x[1]], zip(*val.nonzero()))))),\n",
    "    columns=['user_id', 'movie_id', 'rating']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:37.125911Z",
     "start_time": "2021-01-28T07:14:37.112250Z"
    }
   },
   "outputs": [],
   "source": [
    "# index \"0\" is reserved for unknown ids.\n",
    "user_to_index = defaultdict(lambda : 0, { uid: i+1 for i,uid in enumerate(np.unique(df_train.user_id)) })\n",
    "movie_to_index = defaultdict(lambda: 0, { mid: i+1 for i,mid in enumerate(np.unique(df_train.movie_id))})\n",
    "USER_ID_SIZE = len(user_to_index) + 1\n",
    "MOVIE_ID_SIZE = len(movie_to_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:37.327662Z",
     "start_time": "2021-01-28T07:14:37.162284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Implement side information and flavor of SVD++\n",
    "# We add \"all users who have evaluated a movie in the train set\" or\n",
    "# \"all movies rated by a user\" as a feture of user/movie.\n",
    "use_date = False # use date info or not\n",
    "use_iu = True # use implicit user feature\n",
    "use_ii = True # use implicit item feature\n",
    "use_user_info = False # use user information\n",
    "use_movie_info = False # use movie information\n",
    "\n",
    "movie_vs_watched = dict()\n",
    "user_vs_watched = dict()\n",
    "for row in df_train.itertuples():\n",
    "    user_id = row.user_id\n",
    "    movie_id = row.movie_id\n",
    "    movie_vs_watched.setdefault(movie_id, list()).append(user_id)\n",
    "    user_vs_watched.setdefault(user_id, list()).append(movie_id)\n",
    "\n",
    "if use_date:\n",
    "    X_date_train = categorize_date(df_train)\n",
    "    X_date_test  = categorize_date(df_test)\n",
    "else:\n",
    "    X_date_train, X_date_test = (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:38.407115Z",
     "start_time": "2021-01-28T07:14:38.402810Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup grouping\n",
    "feature_group_sizes = []\n",
    "if use_date:\n",
    "    feature_group_sizes.append(\n",
    "        len(date_be.categories_[0]), # date\n",
    "    )\n",
    "\n",
    "feature_group_sizes.append(USER_ID_SIZE) # user ids\n",
    "\n",
    "if use_iu:\n",
    "    feature_group_sizes.append(MOVIE_ID_SIZE)\n",
    "\n",
    "if use_user_info:\n",
    "    feature_group_sizes.extend([\n",
    "        len(c) for c in user_info_ohe.categories_ # user attributes\n",
    "    ])\n",
    "\n",
    "feature_group_sizes.append(MOVIE_ID_SIZE) # movie ids\n",
    "                           \n",
    "if use_ii:\n",
    "    feature_group_sizes.append(USER_ID_SIZE)\n",
    "\n",
    "if use_movie_info:\n",
    "    feature_group_sizes.extend([\n",
    "        len(c) for c in movie_info_ohe.categories_ # user attributes\n",
    "    ])\n",
    "    feature_group_sizes.append(len(movie_genres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:39.367588Z",
     "start_time": "2021-01-28T07:14:39.357315Z"
    }
   },
   "outputs": [],
   "source": [
    "# given user/movie ids, add additional infos and return it as sparse\n",
    "def augment_user_id(user_ids):\n",
    "    Xs = []\n",
    "    X_uid = sps.lil_matrix((len(user_ids), USER_ID_SIZE))\n",
    "    for index, user_id in enumerate(user_ids):\n",
    "        X_uid[index, user_to_index[user_id]] = 1\n",
    "    Xs.append(X_uid)\n",
    "    if use_iu:\n",
    "        X_iu = sps.lil_matrix((len(user_ids), MOVIE_ID_SIZE))\n",
    "        for index, user_id in enumerate(user_ids):\n",
    "            watched_movies = user_vs_watched.get(user_id, [])\n",
    "            normalizer = 1 / max(len(watched_movies), 1) ** 0.5\n",
    "            for uid in watched_movies:\n",
    "                X_iu[index, movie_to_index[uid]] = normalizer\n",
    "        Xs.append(X_iu)\n",
    "    if use_user_info:\n",
    "        Xs.append(user_info_ohe.transform(user_info.reindex(user_ids)))\n",
    "    return sps.hstack(Xs, format='csr')\n",
    "\n",
    "def augment_movie_id(movie_ids):\n",
    "    Xs = []\n",
    "    X_movie = sps.lil_matrix((len(movie_ids), MOVIE_ID_SIZE))\n",
    "    for index, movie_id in enumerate(movie_ids):\n",
    "        X_movie[index, movie_to_index[movie_id]] = 1\n",
    "    Xs.append(X_movie)\n",
    "    \n",
    "    if use_ii:\n",
    "        X_ii = sps.lil_matrix((len(movie_ids), USER_ID_SIZE))\n",
    "        for index, movie_id in enumerate(movie_ids):\n",
    "            watched_users = movie_vs_watched.get(movie_id, [])\n",
    "            normalizer = 1 / max(len(watched_users), 1) ** 0.5\n",
    "            for uid in watched_users:\n",
    "                X_ii[index, user_to_index[uid]] = normalizer\n",
    "        Xs.append(X_ii)    \n",
    "    \n",
    "    if use_movie_info:\n",
    "        Xs.append(movie_info_ohe.transform(movie_info.drop(columns=movie_genres).reindex(movie_ids)))\n",
    "        Xs.append(sps.csr_matrix(movie_info.reindex(movie_ids)[movie_genres].values))\n",
    "    return sps.hstack(Xs, format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Relation Block to express data\n",
    "See [\\[Rendle 2013\\]](http://www.vldb.org/pvldb/vol6/p337-rendle.pdf) how comlexity dcrease drastically in this case (and most cases with bipartite graph structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:14:42.640998Z",
     "start_time": "2021-01-28T07:14:40.979237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create RelationBlock.\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.unique.html\n",
    "train_blocks = []\n",
    "test_blocks = []\n",
    "for source, target in [(df_train, train_blocks), (df_test, test_blocks)]:\n",
    "    unique_users, user_map = np.unique(source.user_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(user_map, augment_user_id(unique_users))\n",
    "    )\n",
    "    unique_movies, movie_map = np.unique(source.movie_id, return_inverse=True)\n",
    "    target.append(\n",
    "        RelationBlock(movie_map, augment_movie_id(unique_movies))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:15:02.589251Z",
     "start_time": "2021-01-28T07:14:42.752790Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alpha = 2.74 w0 = 3.65  rmse_this: 0.81 mae_this: 0.64: 100%|██████████| 300/300 [00:19<00:00, 15.14it/s]\n"
     ]
    }
   ],
   "source": [
    "fm = myfm.MyFMRegressor(rank=10)\n",
    "fm.fit(\n",
    "    X_date_train, df_train.rating.values, X_rel=train_blocks, X_test=X_date_test, X_rel_test=test_blocks,\n",
    "    y_test=df_test.rating.values,\n",
    "    n_iter=300, n_kept_samples=295\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:15:27.508165Z",
     "start_time": "2021-01-28T07:15:25.767006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=0.7212\n"
     ]
    }
   ],
   "source": [
    "test_predictions = fm.predict(X_date_test, test_blocks)\n",
    "test_predictions = np.clip(test_predictions, 1., 5.)\n",
    "\n",
    "rmse = (\n",
    "    (test_predictions - df_test.rating.values)**2\n",
    ").mean() ** 0.5\n",
    "\n",
    "print('rmse={:.4f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordered Probit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:18:09.225245Z",
     "start_time": "2021-01-28T07:17:28.908509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w0= 0.226519, cutpoint = ['-2.971', '-1.836', '0.045', '1.648'] : 100%|██████████| 300/300 [00:40<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "fm_probit = myfm.MyFMOrderedProbit(rank=10)\n",
    "fm_probit.fit(\n",
    "    X_date_train, df_train.rating.values - 1, X_rel=train_blocks,\n",
    "    n_iter=300, n_kept_samples=295\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T07:18:09.602548Z",
     "start_time": "2021-01-28T07:18:09.338605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/sputils.py:114: UserWarning: object dtype is not supported by sparse matrices\n",
      "  warnings.warn(\"object dtype is not supported by sparse matrices\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Relation blocks have inconsistent mapper size with case_size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-1aab4d319be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_prediction_ordered_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm_probit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_date_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_prediction_ordered_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_prediction_ordered_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# class 0 => rating 1 shift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m rmse = (\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtest_prediction_ordered_mean\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/myfm/wrapper.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, rels, cutpoint_index, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_offset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             score = std_cdf(\n\u001b[1;32m    391\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcutpoint_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Relation blocks have inconsistent mapper size with case_size"
     ]
    }
   ],
   "source": [
    "test_prediction_ordered_prob = fm_probit.predict_proba(X_date_test, test_blocks)\n",
    "test_prediction_ordered_mean = 1 + test_prediction_ordered_prob.dot(np.arange(5)) # class 0 => rating 1 shift\n",
    "\n",
    "rmse = (\n",
    "    (test_prediction_ordered_mean - df_test.rating.values) ** 2\n",
    ").mean() ** 0.5\n",
    "mae = np.abs(test_prediction_ordered_mean - df_test.rating).mean()\n",
    "test_predictions = fm.predict(X_date_test, test_blocks)\n",
    "\n",
    "print('rmse={}, mae={}'.format(rmse, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
